{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
      "Requirement already satisfied: tensorflow in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (2.16.2)\n",
      "Requirement already satisfied: pandas in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: tabulate in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (0.9.0)\n",
      "Requirement already satisfied: shap in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (0.47.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (1.5.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (4.67.0)\n",
      "Requirement already satisfied: numba>=0.54 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: namex in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: optree in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install seaborn tensorflow pandas tabulate shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-05-01 01:52:49.610524: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.610550: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.610556: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.610574: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.610586: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:49.611952: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.611973: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.611978: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.611988: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.611993: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.612000: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.612004: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.612004: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:49.612015: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.612023: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:49.612718: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.612735: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.612738: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.612750: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.612758: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:49.612787: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.612804: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.612809: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.612823: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.612833: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:49.627683: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.627716: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.627731: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.627755: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.627769: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:49.631018: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.631070: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.631079: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.631115: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.631135: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:49.634183: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:52:49.634201: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:52:49.634206: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:52:49.634220: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:52:49.634229: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:52:50.154618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-01 01:52:50.155116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-01 01:52:50.155984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-01 01:52:50.159058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-01 01:52:50.159520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-01 01:52:50.159774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-01 01:52:50.166333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-01 01:52:50.167393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META: Walk-forward steps: 100%|##########| 1064/1064 [01:45<00:00, 10.05it/s]\n",
      "GOOG: Walk-forward steps: 100%|##########| 1064/1064 [02:12<00:00,  8.05it/s]]\n",
      "GOOGL: Walk-forward steps: 100%|##########| 1064/1064 [02:12<00:00,  8.00it/s]\n",
      "AMZN: Walk-forward steps: 100%|##########| 1083/1083 [02:27<00:00,  7.35it/s]]\n",
      "BRK-B: Walk-forward steps: 100%|##########| 1083/1083 [02:28<00:00,  7.30it/s]\n",
      "NVDA: Walk-forward steps: 100%|##########| 1083/1083 [02:28<00:00,  7.30it/s]\n",
      "AAPL: Walk-forward steps: 100%|##########| 1083/1083 [02:28<00:00,  7.28it/s]\n",
      "MSFT: Walk-forward steps: 100%|##########| 1083/1083 [02:28<00:00,  7.27it/s]\n",
      "AVGO: Walk-forward steps: 100%|##########| 1064/1064 [01:59<00:00,  8.89it/s]\n",
      "XOM: Walk-forward steps:  54%|#####4    | 588/1083 [01:14<00:16, 29.84it/s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA: Walk-forward steps:  59%|#####8    | 624/1064 [01:16<00:46,  9.42it/s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA: Walk-forward steps:  64%|######3   | 678/1064 [01:18<00:14, 26.52it/s]s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:56:58.834929: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:56:58.834948: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:56:58.834953: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:56:58.834969: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:56:58.834979: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA: Walk-forward steps:  88%|########8 | 937/1064 [01:40<00:06, 20.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:56:59.537781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA: Walk-forward steps: 100%|##########| 1064/1064 [01:56<00:00,  9.14it/s]\n",
      "LLY: Walk-forward steps:  74%|#######4  | 803/1083 [01:57<05:36,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPM: Walk-forward steps:  69%|######9   | 751/1083 [01:44<00:16, 20.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:57:23.876827: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:57:23.876852: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:57:23.876859: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:57:23.876874: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:57:23.876884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA: Walk-forward steps:  84%|########3 | 892/1064 [01:44<00:05, 30.30it/s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:57:24.492359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V: Walk-forward steps: 100%|##########| 1064/1064 [02:02<00:00,  8.70it/s]]\n",
      "MA: Walk-forward steps: 100%|##########| 1064/1064 [02:13<00:00,  7.99it/s]]\n",
      "LLY: Walk-forward steps: 100%|##########| 1083/1083 [02:31<00:00,  7.16it/s]\n",
      "WMT: Walk-forward steps:  92%|#########2| 999/1083 [02:15<00:02, 30.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-05-01 01:58:01.319955: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:58:01.319984: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:58:01.319991: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:58:01.320008: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:58:01.320020: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-01 01:58:02.073114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOM: Walk-forward steps: 100%|##########| 1083/1083 [02:28<00:00,  7.28it/s]\n",
      "JPM: Walk-forward steps: 100%|##########| 1083/1083 [02:30<00:00,  7.18it/s]\n",
      "WMT: Walk-forward steps: 100%|##########| 1083/1083 [02:29<00:00,  7.24it/s]\n",
      "ORCL: Walk-forward steps:  30%|###       | 330/1083 [00:43<00:59, 12.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JNJ: Walk-forward steps:   9%|9         | 101/1083 [00:10<12:05,  1.35it/s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-05-01 01:58:19.502064: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:58:19.502085: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:58:19.502090: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:58:19.502105: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:58:19.502115: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX: Walk-forward steps:  22%|##2       | 237/1064 [00:27<00:46, 17.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:58:20.113454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNH: Walk-forward steps:  53%|#####3    | 579/1083 [01:11<00:16, 29.95it/s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:58:20.656608: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-01 01:58:20.656633: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-05-01 01:58:20.656639: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-05-01 01:58:20.656656: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-01 01:58:20.656667: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG: Walk-forward steps:   2%|1         | 21/1083 [00:00<00:35, 30.00it/s]s]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:58:21.225929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNH: Walk-forward steps: 100%|##########| 1083/1083 [02:26<00:00,  7.38it/s]\n",
      "ORCL: Walk-forward steps: 100%|##########| 1083/1083 [02:28<00:00,  7.28it/s]\n",
      "ABBV: Walk-forward steps: 100%|##########| 1064/1064 [01:44<00:00, 10.17it/s]\n",
      "NFLX: Walk-forward steps: 100%|##########| 1064/1064 [02:24<00:00,  7.38it/s]\n",
      "JNJ: Walk-forward steps: 100%|##########| 1083/1083 [02:22<00:00,  7.62it/s]\n",
      "COST: Walk-forward steps: 100%|##########| 1083/1083 [02:24<00:00,  7.51it/s]\n",
      "PG: Walk-forward steps: 100%|##########| 1083/1083 [02:22<00:00,  7.59it/s]\n",
      "HD: Walk-forward steps: 100%|##########| 1083/1083 [02:18<00:00,  7.84it/s]\n",
      "BAC: Walk-forward steps: 100%|##########| 1083/1083 [01:59<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  25 out of  25 | elapsed:  9.1min finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import atexit\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "import contextlib\n",
    "from io import StringIO\n",
    "from joblib import Parallel, delayed\n",
    "import cloudpickle\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# Enable mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Configuration for Hyperparameter Set 1\n",
    "CONFIG = {\n",
    "    'input_csv': '../../data/daily_stock_price/sp500_top25_technical_indicators.csv',\n",
    "    'output_csv': 'transformer_evaluation_results_walk_forward.csv',\n",
    "    'target': 'Close',\n",
    "    'look_back': 60,\n",
    "    'forecast_horizon': 1,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 10,\n",
    "    'walkforward_retrain_step': 100,\n",
    "    'train_start': '2001-01-01',\n",
    "    'train_end': '2020-12-31',\n",
    "    'test_start': '2021-01-01',\n",
    "    'hyperparam_set': 2\n",
    "}\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'Close', 'SMA_20', 'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "    'BB_Upper', 'BB_Lower', 'ATR_14', 'OBV',\n",
    "    'Close_Lag_1', 'Close_Lag_2', 'Close_Lag_3', 'Close_Lag_5',\n",
    "    'Volume_Lag_1', 'Volume_Lag_3', 'Daily_Return', 'Volatility_20',\n",
    "    'High_Low_Range', 'Open_Close_Range', 'MACD_Hist_Slope'\n",
    "]\n",
    "\n",
    "# Custom stream for logging TensorFlow output\n",
    "class LogStream:\n",
    "    def __init__(self, logger, level=logging.INFO):\n",
    "        self.logger = logger\n",
    "        self.level = level\n",
    "        self.buffer = StringIO()\n",
    "\n",
    "    def write(self, message):\n",
    "        self.buffer.write(message)\n",
    "        if '\\n' in message:\n",
    "            self.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        message = self.buffer.getvalue().rstrip()\n",
    "        if message:\n",
    "            self.logger.log(self.level, message)\n",
    "        self.buffer.seek(0)\n",
    "        self.buffer.truncate()\n",
    "\n",
    "# Custom stream for tqdm to allow cell output\n",
    "class TqdmStream:\n",
    "    def write(self, message):\n",
    "        sys.__stdout__.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        sys.__stdout__.flush()\n",
    "\n",
    "# Create log file with timestamp\n",
    "log_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.makedirs(\"log\", exist_ok=True)\n",
    "log_filename = os.path.join(\"log\", f\"transformer_log_set_{CONFIG['hyperparam_set']}_{log_time}.txt\")\n",
    "file_handler = logging.FileHandler(log_filename, mode='w')\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.ERROR)  # Only show errors in cell output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(processName)s - %(levelname)s - %(message)s',\n",
    "    handlers=[file_handler, stream_handler]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "atexit.register(lambda: [h.flush() for h in logger.handlers if hasattr(h, 'flush')])\n",
    "\n",
    "# Custom callback for detailed epoch logging with loss collection\n",
    "class EpochLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, stock, hyperparam_set, walkforward_step=None):\n",
    "        super(EpochLogger, self).__init__()\n",
    "        self.stock = stock\n",
    "        self.hyperparam_set = hyperparam_set\n",
    "        self.walkforward_step = walkforward_step\n",
    "        self.context = f\"walk-forward step {walkforward_step}\" if walkforward_step is not None else \"initial training\"\n",
    "        self.epoch_losses = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        logger.info(f\"Starting epoch {epoch + 1} for {self.stock} (Hyperparameter Set {self.hyperparam_set}, {self.context})\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss = logs.get('loss', 'N/A')\n",
    "        self.epoch_losses.append({'epoch': epoch + 1, 'loss': loss})\n",
    "        logger.info(f\"Finished epoch {epoch + 1} for {self.stock} (Hyperparameter Set {self.hyperparam_set}, {self.context}) - Loss: {loss:.6f}\")\n",
    "\n",
    "def build_transformer_with_attention(look_back, n_features):\n",
    "    inputs = tf.keras.Input(shape=(look_back, n_features))\n",
    "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=16)(inputs, inputs)\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    prediction = tf.keras.layers.Dense(1, dtype='float32')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=prediction)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_sequences(data, look_back, forecast_horizon, target_index=0):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - forecast_horizon + 1):\n",
    "        X.append(data[i:i+look_back, :])\n",
    "        y.append(data[i + look_back:i + look_back + forecast_horizon, target_index])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "def process_stock(stock, df, hyperparam_set, saliency_dir, config):\n",
    "    os.makedirs(saliency_dir, exist_ok=True)\n",
    "    start_time = time.time()\n",
    "    retrain_count = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Processing {stock} for hyperparameter set {hyperparam_set}...\")\n",
    "        stock_df = df[df['symbol'] == stock].copy()\n",
    "        stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
    "        stock_df = stock_df[(stock_df['date'] >= config['train_start'])]\n",
    "        stock_df.sort_values('date', inplace=True)\n",
    "        stock_df.set_index('date', inplace=True)\n",
    "\n",
    "        features = stock_df[FEATURE_COLUMNS].dropna()\n",
    "        if features.empty:\n",
    "            logger.warning(f\"{stock}: No data after dropping NaNs, skipping.\")\n",
    "            return None\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        target_index = FEATURE_COLUMNS.index(config['target'])\n",
    "        X, y = create_sequences(features_scaled, config['look_back'], config['forecast_horizon'], target_index)\n",
    "\n",
    "        dates = stock_df.index[config['look_back'] + config['forecast_horizon'] - 1:]\n",
    "        date_mask = (dates >= pd.to_datetime(config['test_start']))\n",
    "        if not any(date_mask):\n",
    "            logger.warning(f\"{stock}: No test data after {config['test_start']}, skipping.\")\n",
    "            return None\n",
    "\n",
    "        split_idx = np.where(date_mask)[0][0]\n",
    "        X_train_full, y_train_full = X[:split_idx], y[:split_idx]\n",
    "        X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train_full, y_train_full))\n",
    "        train_dataset = train_dataset.cache().shuffle(1000).batch(config['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "        epoch_logger = EpochLogger(stock, hyperparam_set)\n",
    "        model = build_transformer_with_attention(config['look_back'], X.shape[2])\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(x, y):\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(x, training=True)\n",
    "                loss = model.loss(y, predictions)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            return loss\n",
    "\n",
    "        log_stream = LogStream(logger)\n",
    "        with contextlib.redirect_stdout(log_stream):\n",
    "            model.fit(train_dataset, epochs=config['epochs'], callbacks=[early_stop, epoch_logger], verbose=1)\n",
    "        epoch_losses.extend([{'ticker': stock, **loss} for loss in epoch_logger.epoch_losses])\n",
    "\n",
    "        predictions = []\n",
    "        history_X, history_y = X_train_full.tolist(), y_train_full.tolist()\n",
    "\n",
    "        for i in tqdm(range(len(X_test)), desc=f\"{stock}: Walk-forward steps\", file=TqdmStream()):\n",
    "            if i % config['walkforward_retrain_step'] == 0 and i > 0:\n",
    "                logger.info(f\"Starting retraining for {stock} at walk-forward step {i} (Hyperparameter Set {hyperparam_set})\")\n",
    "                model = build_transformer_with_attention(config['look_back'], X.shape[2])\n",
    "                epoch_logger = EpochLogger(stock, hyperparam_set, walkforward_step=i)\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((np.array(history_X, dtype=np.float32), np.array(history_y, dtype=np.float32)))\n",
    "                train_dataset = train_dataset.cache().shuffle(1000).batch(config['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
    "                with contextlib.redirect_stdout(log_stream):\n",
    "                    model.fit(train_dataset, epochs=config['epochs'], callbacks=[early_stop, epoch_logger], verbose=1)\n",
    "                epoch_losses.extend([{'ticker': stock, **loss} for loss in epoch_logger.epoch_losses])\n",
    "                retrain_count += 1\n",
    "                logger.info(f\"Completed retraining for {stock} at walk-forward step {i} (Hyperparameter Set {hyperparam_set})\")\n",
    "\n",
    "            pred = model.predict(X_test[i:i+1], verbose=0, batch_size=1)\n",
    "            predictions.append(pred[0][0])\n",
    "            history_X.append(X_test[i].tolist())\n",
    "            history_y.append([y_test[i][0]])\n",
    "\n",
    "        preds_2d = np.tile(np.array(predictions)[:, np.newaxis], (1, X.shape[2]))\n",
    "        y_test_flat = y_test[:, 0]\n",
    "        y_true_2d = np.tile(y_test_flat[:, np.newaxis], (1, X.shape[2]))\n",
    "\n",
    "        preds_inv = scaler.inverse_transform(preds_2d)[:, target_index]\n",
    "        y_true_inv = scaler.inverse_transform(y_true_2d)[:, target_index]\n",
    "\n",
    "        mse = mean_squared_error(y_true_inv, preds_inv)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true_inv, preds_inv)\n",
    "        r2 = r2_score(y_true_inv, preds_inv)\n",
    "\n",
    "        logger.info(f\"{stock} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "        logger.info(f\"{stock}: Done in {time.time() - start_time:.1f}s\")\n",
    "        logger.info(f\"{stock}: Completed {config['epochs']} initial epochs and {retrain_count} retraining steps (Hyperparameter Set {hyperparam_set})\")\n",
    "\n",
    "        saliency = None\n",
    "        try:\n",
    "            input_sample = X_test[-1]\n",
    "            input_tensor = tf.convert_to_tensor(input_sample[np.newaxis, ...], dtype=tf.float32)\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(input_tensor)\n",
    "                prediction = model(input_tensor)\n",
    "            grads = tape.gradient(prediction, input_tensor).numpy()[0]\n",
    "            saliency = np.mean(np.abs(grads), axis=0)\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.barh(FEATURE_COLUMNS, saliency)\n",
    "            plt.xlabel(\"Average Absolute Gradient\")\n",
    "            plt.title(f\"Saliency Map - {stock} (Set {hyperparam_set})\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(saliency_dir, f\"saliency_{stock}_set_{hyperparam_set}.png\"))\n",
    "            plt.close()\n",
    "            logger.info(f\"Generated saliency map image for {stock} (Hyperparameter Set {hyperparam_set})\")\n",
    "\n",
    "        except Exception as grad_err:\n",
    "            logger.warning(f\"Saliency map failed for {stock}: {grad_err}\")\n",
    "\n",
    "        # Clear model and memory\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        return {\n",
    "            'Stock': stock,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2,\n",
    "            'Saliency': saliency,\n",
    "            'Epoch_Losses': epoch_losses,\n",
    "            'batch_size': config['batch_size'],\n",
    "            'epochs': config['epochs'],\n",
    "            'walkforward_retrain_step': config['walkforward_retrain_step'],\n",
    "            'hyperparam_set': config['hyperparam_set']\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {stock}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_combined_saliency_plot(saliency_data, hyperparam_set, saliency_dir):\n",
    "    try:\n",
    "        if not saliency_data:\n",
    "            logger.warning(f\"No saliency data for hyperparameter set {hyperparam_set}\")\n",
    "            return\n",
    "        logger.info(f\"Generating combined saliency plot for hyperparameter set {hyperparam_set}\")\n",
    "        avg_saliency = np.mean(np.array(saliency_data), axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.barh(FEATURE_COLUMNS, avg_saliency)\n",
    "        plt.xlabel(\"Average Absolute Gradient\")\n",
    "        plt.title(f\"Combined Saliency Map - All Stocks (Set {hyperparam_set})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(saliency_dir, f\"saliency_combined_set_{hyperparam_set}.png\"))\n",
    "        plt.close()\n",
    "        logger.info(f\"Generated combined saliency map image for all stocks (Hyperparameter Set {hyperparam_set})\")\n",
    "\n",
    "        saliency_df = pd.DataFrame([avg_saliency], columns=FEATURE_COLUMNS)\n",
    "        saliency_csv_path = os.path.join(saliency_dir, f\"saliency_combined_set_{hyperparam_set}.csv\")\n",
    "        saliency_df.to_csv(saliency_csv_path, index=False)\n",
    "        logger.info(f\"Saved combined saliency map CSV to {saliency_csv_path} (Hyperparameter Set {hyperparam_set})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate combined saliency plot for hyperparameter set {hyperparam_set}: {e}\")\n",
    "\n",
    "def train_and_evaluate_transformer():\n",
    "    try:\n",
    "        logger.info(\"Loading input CSV\")\n",
    "        df = pd.read_csv(CONFIG['input_csv'])\n",
    "        all_results = []\n",
    "\n",
    "        stocks = df['symbol'].unique()\n",
    "        logger.info(f\"Processing {len(stocks)} stocks\")\n",
    "\n",
    "        os.makedirs(\"plot\", exist_ok=True)\n",
    "        os.makedirs(\"saliency_outputs\", exist_ok=True)\n",
    "\n",
    "        num_workers = 8\n",
    "\n",
    "        saliency_dir = os.path.join(\"saliency_outputs\", f\"transformer_set_{CONFIG['hyperparam_set']}\")\n",
    "        try:\n",
    "            os.makedirs(saliency_dir, exist_ok=True)\n",
    "            logger.info(f\"Created saliency directory: {saliency_dir}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to create saliency directory {saliency_dir}: {e}\")\n",
    "            return None\n",
    "\n",
    "        logger.info(f\"Starting parallel processing for {len(stocks)} stocks with {num_workers} workers (Hyperparameter Set {CONFIG['hyperparam_set']})\")\n",
    "        try:\n",
    "            results = Parallel(n_jobs=num_workers, backend='loky', verbose=1)(\n",
    "                delayed(process_stock)(stock, df, CONFIG['hyperparam_set'], saliency_dir, CONFIG) for stock in stocks\n",
    "            )\n",
    "            logger.info(f\"Completed parallel processing for {len(stocks)} stocks (Hyperparameter Set {CONFIG['hyperparam_set']})\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Parallel processing failed for hyperparameter set {CONFIG['hyperparam_set']}: {e}\")\n",
    "            return None\n",
    "\n",
    "        logger.info(f\"Processing results for hyperparameter set {CONFIG['hyperparam_set']}\")\n",
    "        saliency_records = []\n",
    "        epoch_loss_records = []\n",
    "        metrics_records = []\n",
    "        for result in results:\n",
    "            if result:\n",
    "                metrics_records.append({\n",
    "                    'Stock': result['Stock'],\n",
    "                    'MSE': result['MSE'],\n",
    "                    'RMSE': result['RMSE'],\n",
    "                    'MAE': result['MAE'],\n",
    "                    'R2': result['R2'],\n",
    "                    'batch_size': result['batch_size'],\n",
    "                    'epochs': result['epochs'],\n",
    "                    'walkforward_retrain_step': result['walkforward_retrain_step'],\n",
    "                    'hyperparam_set': result['hyperparam_set']\n",
    "                })\n",
    "                if result['Saliency'] is not None:\n",
    "                    saliency_records.append({\n",
    "                        'ticker': result['Stock'],\n",
    "                        **dict(zip(FEATURE_COLUMNS, result['Saliency']))\n",
    "                    })\n",
    "                epoch_loss_records.extend(result['Epoch_Losses'])\n",
    "\n",
    "        logger.info(f\"Saving saliency data to CSV for hyperparameter set {CONFIG['hyperparam_set']}\")\n",
    "        try:\n",
    "            if saliency_records:\n",
    "                saliency_df = pd.DataFrame(saliency_records)\n",
    "                saliency_csv_path = os.path.join(saliency_dir, f\"transformer_set_{CONFIG['hyperparam_set']}_saliency.csv\")\n",
    "                saliency_df.to_csv(saliency_csv_path, index=False)\n",
    "                logger.info(f\"Saved saliency data CSV to {saliency_csv_path} (Hyperparameter Set {CONFIG['hyperparam_set']})\")\n",
    "            else:\n",
    "                logger.warning(f\"No saliency data to save for hyperparameter set {CONFIG['hyperparam_set']}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save saliency data CSV for hyperparameter set {CONFIG['hyperparam_set']}: {e}\")\n",
    "\n",
    "        generate_combined_saliency_plot([r['Saliency'] for r in results if r and r['Saliency'] is not None], CONFIG['hyperparam_set'], saliency_dir)\n",
    "\n",
    "        logger.info(f\"Saving metrics to CSV for hyperparameter set {CONFIG['hyperparam_set']}\")\n",
    "        try:\n",
    "            metrics_df = pd.DataFrame(metrics_records)\n",
    "            metrics_csv_path = os.path.join(saliency_dir, f\"transformer_set_{CONFIG['hyperparam_set']}_metrics.csv\")\n",
    "            metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "            logger.info(f\"Saved metrics CSV to {metrics_csv_path} (Hyperparameter Set {CONFIG['hyperparam_set']})\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save metrics CSV for hyperparameter set {CONFIG['hyperparam_set']}: {e}\")\n",
    "\n",
    "        logger.info(f\"Saving epoch metrics to CSV for hyperparameter set {CONFIG['hyperparam_set']}\")\n",
    "        try:\n",
    "            epoch_metrics_df = pd.DataFrame(epoch_loss_records)\n",
    "            epoch_metrics_csv_path = os.path.join(saliency_dir, f\"transformer_set_{CONFIG['hyperparam_set']}_epoch_metrics.csv\")\n",
    "            epoch_metrics_df.to_csv(epoch_metrics_csv_path, index=False)\n",
    "            logger.info(f\"Saved epoch metrics CSV to {epoch_metrics_csv_path} (Hyperparameter Set {CONFIG['hyperparam_set']})\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save epoch metrics CSV for hyperparameter set {CONFIG['hyperparam_set']}: {e}\")\n",
    "\n",
    "        logger.info(f\"Saving summary to CSV for hyperparameter set {CONFIG['hyperparam_set']}\")\n",
    "        try:\n",
    "            summary = metrics_df[['MSE', 'RMSE', 'MAE', 'R2']].mean().to_frame().T\n",
    "            summary['hyperparam_set'] = CONFIG['hyperparam_set']\n",
    "            summary['batch_size'] = CONFIG['batch_size']\n",
    "            summary['epochs'] = CONFIG['epochs']\n",
    "            summary['walkforward_retrain_step'] = CONFIG['walkforward_retrain_step']\n",
    "            summary_csv_path = os.path.join(saliency_dir, f\"transformer_set_{CONFIG['hyperparam_set']}_summary.csv\")\n",
    "            summary.to_csv(summary_csv_path, index=False)\n",
    "            logger.info(f\"Saved summary CSV to {summary_csv_path} (Hyperparameter Set {CONFIG['hyperparam_set']})\")\n",
    "            logger.info(\"Performance Summary:\")\n",
    "            logger.info(\"\\n\" + tabulate(summary, headers='keys', tablefmt='github', showindex=False))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save summary CSV for hyperparameter set {CONFIG['hyperparam_set']}: {e}\")\n",
    "            return None\n",
    "\n",
    "        logger.info(f\"Clearing memory after hyperparameter set {CONFIG['hyperparam_set']}\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        return metrics_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed: {e}\")\n",
    "        return None\n",
    "\n",
    "logger.info(\"Starting Transformer model training and evaluation...\")\n",
    "try:\n",
    "    result_df = train_and_evaluate_transformer()\n",
    "    if result_df is not None:\n",
    "        logger.info(\"Evaluation complete.\")\n",
    "        logger.info(\"\\n\" + result_df.to_string())\n",
    "except Exception as e:\n",
    "    logger.error(f\"Training failed: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
