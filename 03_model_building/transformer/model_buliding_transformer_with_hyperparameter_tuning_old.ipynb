{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
      "Requirement already satisfied: tensorflow in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (2.16.2)\n",
      "Requirement already satisfied: pandas in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: tabulate in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (0.9.0)\n",
      "Requirement already satisfied: shap in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (0.47.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: packaging in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: scikit-learn in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (1.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (4.67.0)\n",
      "Requirement already satisfied: numba>=0.54 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: scipy in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: namex in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: rich in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/kwklun/Library/Python/3.9/lib/python/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install seaborn tensorflow pandas tabulate shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwklun/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Set 1 - Evaluating stocks:   0%|          | 0/3 [00:00<?, ?it/s]2025-04-30 23:17:32.326137: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-04-30 23:17:32.326161: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-04-30 23:17:32.326173: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-04-30 23:17:32.326187: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-30 23:17:32.326197: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-04-30 23:17:32.839140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "Set 1 - Evaluating stocks: 100%|██████████| 3/3 [03:28<00:00, 69.59s/it]\n",
      "Set 2 - Evaluating stocks: 100%|██████████| 3/3 [05:55<00:00, 118.66s/it]\n",
      "Set 3 - Evaluating stocks: 100%|██████████| 3/3 [10:44<00:00, 214.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Summary:\n",
      "|   Hyperparam_Set |     MSE |    RMSE |     MAE |        R2 |\n",
      "|------------------|---------|---------|---------|-----------|\n",
      "|                1 | 5691.55 | 63.882  | 51.2802 | -0.619001 |\n",
      "|                2 | 3309.57 | 54.118  | 41.2375 | -0.25774  |\n",
      "|                3 | 3078.97 | 50.6133 | 40.0437 | -0.142662 |\n",
      "  Stock           MSE        RMSE         MAE        R2  batch_size  epochs  \\\n",
      "0  AAPL   1790.528584   42.314638   32.411157 -0.547743          64       1   \n",
      "1  MSFT  14431.471026  120.131058  101.527092 -1.849819          64       1   \n",
      "2  NVDA    852.653404   29.200230   19.902350  0.540558          64       1   \n",
      "3  AAPL   2062.027810   45.409556   36.622950 -0.782428         128       2   \n",
      "4  MSFT   6585.523961   81.151241   63.522297 -0.300460         128       2   \n",
      "5  NVDA   1281.147262   35.793118   23.567167  0.309669         128       2   \n",
      "6  AAPL   2067.124688   45.465643   35.058787 -0.786834         256       3   \n",
      "7  MSFT   6509.723221   80.682856   66.294269 -0.285491         256       3   \n",
      "8  NVDA    660.053078   25.691498   18.778072  0.644338         256       3   \n",
      "\n",
      "   walkforward_retrain_step  Hyperparam_Set  \n",
      "0                       100               1  \n",
      "1                       100               1  \n",
      "2                       100               1  \n",
      "3                        50               2  \n",
      "4                        50               2  \n",
      "5                        50               2  \n",
      "6                        25               3  \n",
      "7                        25               3  \n",
      "8                        25               3  \n"
     ]
    }
   ],
   "source": [
    "# Updated Transformer pipeline with Saliency Maps (Input Gradient Attribution)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import atexit\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Create log file with timestamp\n",
    "log_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.makedirs(\"log\", exist_ok=True)\n",
    "log_filename = os.path.join(\"log\", f\"transformer_log_{log_time}.txt\")\n",
    "file_handler = logging.FileHandler(log_filename, mode='w')\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.WARNING)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(processName)s - %(levelname)s - %(message)s',\n",
    "    handlers=[file_handler, stream_handler]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "atexit.register(lambda: [h.flush() for h in logger.handlers if hasattr(h, 'flush')])\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'input_csv': '../../data/daily_stock_price/sp500_top25_technical_indicators.csv',\n",
    "    'output_csv': 'transformer_evaluation_results_walk_forward.csv',\n",
    "    'target': 'Close',\n",
    "    'look_back': 60,\n",
    "    'forecast_horizon': 1,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 1,\n",
    "    'walkforward_retrain_step': 100,\n",
    "    'train_start': '2001-01-01',\n",
    "    'train_end': '2020-12-31',\n",
    "    'test_start': '2021-01-01'\n",
    "}\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'Close', 'SMA_20', 'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "    'BB_Upper', 'BB_Lower', 'ATR_14', 'OBV',\n",
    "    'Close_Lag_1', 'Close_Lag_2', 'Close_Lag_3', 'Close_Lag_5',\n",
    "    'Volume_Lag_1', 'Volume_Lag_3', 'Daily_Return', 'Volatility_20',\n",
    "    'High_Low_Range', 'Open_Close_Range', 'MACD_Hist_Slope'\n",
    "]\n",
    "\n",
    "def build_transformer_with_attention(look_back, n_features):\n",
    "    inputs = tf.keras.Input(shape=(look_back, n_features))\n",
    "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=16)(inputs, inputs)\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    prediction = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=prediction)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def create_sequences(data, look_back, forecast_horizon, target_index=0):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - forecast_horizon + 1):\n",
    "        X.append(data[i:i+look_back, :])\n",
    "        y.append(data[i + look_back:i + look_back + forecast_horizon, target_index])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def process_stock(stock, df):\n",
    "    os.makedirs(\"saliency_outputs\", exist_ok=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Processing {stock}...\")\n",
    "        stock_df = df[df['symbol'] == stock].copy()\n",
    "        stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
    "        stock_df = stock_df[(stock_df['date'] >= CONFIG['train_start'])]\n",
    "        stock_df.sort_values('date', inplace=True)\n",
    "        stock_df.set_index('date', inplace=True)\n",
    "\n",
    "        features = stock_df[FEATURE_COLUMNS].dropna()\n",
    "        if features.empty:\n",
    "            logger.warning(f\"{stock}: No data after dropping NaNs, skipping.\")\n",
    "            return None\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        target_index = FEATURE_COLUMNS.index(CONFIG['target'])\n",
    "        X, y = create_sequences(features_scaled, CONFIG['look_back'], CONFIG['forecast_horizon'], target_index)\n",
    "\n",
    "        dates = stock_df.index[CONFIG['look_back'] + CONFIG['forecast_horizon'] - 1:]\n",
    "        date_mask = (dates >= pd.to_datetime(CONFIG['test_start']))\n",
    "        if not any(date_mask):\n",
    "            logger.warning(f\"{stock}: No test data after {CONFIG['test_start']}, skipping.\")\n",
    "            return None\n",
    "\n",
    "        split_idx = np.where(date_mask)[0][0]\n",
    "        X_train_full, y_train_full = X[:split_idx], y[:split_idx]\n",
    "        X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
    "        model = build_transformer_with_attention(CONFIG['look_back'], X.shape[2])\n",
    "        model.fit(X_train_full, y_train_full, epochs=CONFIG['epochs'], batch_size=CONFIG['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "\n",
    "        predictions = []\n",
    "        history_X, history_y = X_train_full.tolist(), y_train_full.tolist()\n",
    "\n",
    "        for i in tqdm(range(len(X_test)), desc=f\"{stock}: Walk-forward steps\", leave=False):\n",
    "            if i % CONFIG['walkforward_retrain_step'] == 0 and i > 0:\n",
    "                model = build_transformer_with_attention(CONFIG['look_back'], X.shape[2])\n",
    "                model.fit(np.array(history_X), np.array(history_y), epochs=CONFIG['epochs'], batch_size=CONFIG['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "\n",
    "            pred = model.predict(X_test[i:i+1], verbose=0)\n",
    "            predictions.append(pred[0][0])\n",
    "            history_X.append(X_test[i].tolist())\n",
    "            history_y.append([y_test[i][0]])\n",
    "\n",
    "        preds_2d = np.tile(np.array(predictions)[:, np.newaxis], (1, X.shape[2]))\n",
    "        y_test_flat = y_test[:, 0]\n",
    "        y_true_2d = np.tile(y_test_flat[:, np.newaxis], (1, X.shape[2]))\n",
    "\n",
    "        preds_inv = scaler.inverse_transform(preds_2d)[:, target_index]\n",
    "        y_true_inv = scaler.inverse_transform(y_true_2d)[:, target_index]\n",
    "\n",
    "        mse = mean_squared_error(y_true_inv, preds_inv)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true_inv, preds_inv)\n",
    "        r2 = r2_score(y_true_inv, preds_inv)\n",
    "\n",
    "        logger.info(f\"{stock} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "        logger.info(f\"{stock}: Done in {time.time() - start_time:.1f}s\")\n",
    "\n",
    "        try:\n",
    "            input_sample = X_test[-1]\n",
    "            input_tensor = tf.convert_to_tensor(input_sample[np.newaxis, ...])\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(input_tensor)\n",
    "                prediction = model(input_tensor)\n",
    "            grads = tape.gradient(prediction, input_tensor).numpy()[0]\n",
    "            saliency = np.mean(np.abs(grads), axis=0)\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.barh(FEATURE_COLUMNS, saliency)\n",
    "            plt.xlabel(\"Average Absolute Gradient\")\n",
    "            plt.title(f\"Saliency Map - {stock}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(\"saliency_outputs\", f\"saliency_{stock}.png\"))\n",
    "            plt.close()\n",
    "        except Exception as grad_err:\n",
    "            logger.warning(f\"Saliency map failed for {stock}: {grad_err}\")\n",
    "\n",
    "        return {'Stock': stock, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {stock}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_saliency_dashboard(output_dir=\"saliency_outputs\", output_html=\"saliency_dashboard.html\"):\n",
    "    saliency_files = [f for f in os.listdir(output_dir) if f.startswith(\"saliency_\") and f.endswith(\".png\")]\n",
    "    with open(output_html, \"w\") as f:\n",
    "        f.write(\"<html><head><title>Saliency Map Dashboard</title></head><body>\")\n",
    "        f.write(\"<h1>Saliency Maps</h1>\")\n",
    "        for img_file in sorted(saliency_files):\n",
    "            f.write(f\"<h2>{img_file.replace('saliency_', '').replace('.png', '')}</h2>\")\n",
    "            f.write(f\"<img src='{os.path.join(output_dir, img_file)}' style='width:800px'><hr/>\")\n",
    "        f.write(\"</body></html>\")\n",
    "\n",
    "def train_and_evaluate_transformer():\n",
    "    hyperparams = [\n",
    "        {'batch_size': 64, 'epochs': 1, 'walkforward_retrain_step': 100},\n",
    "        {'batch_size': 128, 'epochs': 2, 'walkforward_retrain_step': 50},\n",
    "        {'batch_size': 256, 'epochs': 3, 'walkforward_retrain_step': 25}\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv(CONFIG['input_csv'])\n",
    "    all_results = []\n",
    "\n",
    "    subset_stocks = ['AAPL', 'MSFT', 'NVDA']\n",
    "    stocks = [s for s in df['symbol'].unique() if s in subset_stocks]\n",
    "\n",
    "    for idx, params in enumerate(hyperparams):\n",
    "        logger.info(f\">>> Running Hyperparameter Set {idx+1}: {params}\")\n",
    "        CONFIG.update(params)\n",
    "        results = []\n",
    "\n",
    "        for stock in tqdm(stocks, desc=f\"Set {idx+1} - Evaluating stocks\"):\n",
    "            result = process_stock(stock, df)\n",
    "            if result:\n",
    "                result.update(params)\n",
    "                results.append(result)\n",
    "\n",
    "        result_df = pd.DataFrame(results)\n",
    "        output_path = CONFIG['output_csv'].replace('.csv', f'_set{idx+1}.csv')\n",
    "        header = not os.path.exists(output_path) or os.path.getsize(output_path) == 0\n",
    "        result_df.to_csv(output_path, index=False, mode='a', header=header)\n",
    "        all_results.append(result_df.assign(Hyperparam_Set=idx+1))\n",
    "\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    summary = final_df.groupby(\"Hyperparam_Set\")[['MSE', 'RMSE', 'MAE', 'R2']].mean().reset_index()\n",
    "    print(\"Performance Summary:\")\n",
    "    print(tabulate(summary, headers='keys', tablefmt='github', showindex=False))\n",
    "\n",
    "    for metric in ['MSE', 'RMSE', 'MAE', 'R2']:\n",
    "        plt.figure()\n",
    "        sns.barplot(data=summary, x='Hyperparam_Set', y=metric)\n",
    "        plt.title(f'Mean {metric} by Hyperparameter Set')\n",
    "        plt.savefig(f'plot_{metric.lower()}.png')\n",
    "        plt.close()\n",
    "\n",
    "    generate_saliency_dashboard()\n",
    "    return final_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger.info(\"Starting Transformer model training and evaluation...\")\n",
    "    result_df = train_and_evaluate_transformer()\n",
    "    if result_df is not None:\n",
    "        logger.info(\"Evaluation complete.\")\n",
    "        print(result_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
