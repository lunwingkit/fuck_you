{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a13c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install seaborn tensorflow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import atexit\n",
    "import math\n",
    "\n",
    "# Create log directory and file with timestamp\n",
    "log_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = \"log\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_filename = os.path.join(log_dir, f\"transformer_log_{log_time}.txt\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(processName)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename, mode='w')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure log handlers are flushed on exit\n",
    "atexit.register(lambda: [h.flush() for h in logger.handlers if hasattr(h, 'flush')])\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'input_csv': '../../data/daily_stock_price/sp500_top25_technical_indicators.csv',\n",
    "    'output_csv': 'transformer_evaluation_results_walk_forward.csv',\n",
    "    'target': 'Close',\n",
    "    'look_back': 60,\n",
    "    'forecast_horizon': 1,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 1,\n",
    "    'walkforward_retrain_step': 100,\n",
    "    'train_start': '2001-01-01',\n",
    "    'train_end': '2020-12-31',\n",
    "    'test_start': '2021-01-01'\n",
    "}\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'Close', 'SMA_20', 'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "    'BB_Upper', 'BB_Lower', 'ATR_14', 'OBV',\n",
    "    'Close_Lag_1', 'Close_Lag_2', 'Close_Lag_3', 'Close_Lag_5',\n",
    "    'Volume_Lag_1', 'Volume_Lag_3', 'Daily_Return', 'Volatility_20',\n",
    "    'High_Low_Range', 'Open_Close_Range', 'MACD_Hist_Slope'\n",
    "]\n",
    "\n",
    "def build_transformer_with_attention(look_back, n_features):\n",
    "    inputs = tf.keras.Input(shape=(look_back, n_features))\n",
    "    attention_layer = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=16, name='attention')\n",
    "    attn_output, attn_scores = attention_layer(inputs, inputs, return_attention_scores=True)\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    prediction = tf.keras.layers.Dense(1, name='prediction')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[prediction, attn_scores])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'prediction': 'mse', 'attention': None},\n",
    "        loss_weights={'prediction': 1.0, 'attention': 0.0}\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def create_sequences(data, look_back, forecast_horizon, target_index=0):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - forecast_horizon + 1):\n",
    "        X.append(data[i:i+look_back, :])\n",
    "        y.append(data[i + look_back:i + look_back + forecast_horizon, target_index])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def process_stock(stock, df):\n",
    "    try:\n",
    "        logger.info(f\"Processing {stock}...\")\n",
    "        print(f\"Starting {stock}...\")  # Indicate stock start in cell output\n",
    "        stock_df = df[df['symbol'] == stock].copy()\n",
    "        stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
    "        stock_df = stock_df[(stock_df['date'] >= CONFIG['train_start'])]\n",
    "        stock_df.sort_values('date', inplace=True)\n",
    "        stock_df.set_index('date', inplace=True)\n",
    "\n",
    "        features = stock_df[FEATURE_COLUMNS].dropna()\n",
    "        if features.empty:\n",
    "            logger.warning(f\"No valid data for {stock} after preprocessing.\")\n",
    "            return None\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        target_index = FEATURE_COLUMNS.index(CONFIG['target'])\n",
    "        X, y = create_sequences(features_scaled, CONFIG['look_back'], CONFIG['forecast_horizon'], target_index)\n",
    "\n",
    "        dates = stock_df.index[CONFIG['look_back'] + CONFIG['forecast_horizon'] - 1:]\n",
    "        date_mask = (dates >= pd.to_datetime(CONFIG['test_start']))\n",
    "        split_idx = np.where(date_mask)[0][0] if any(date_mask) else len(X)\n",
    "\n",
    "        X_train_full, y_train_full = X[:split_idx], y[:split_idx]\n",
    "        X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "        # Calculate total work units: training (fixed) + test steps\n",
    "        training_work = 100  # Arbitrary units for training\n",
    "        test_work = len(X_test)  # One unit per test step\n",
    "        total_work = training_work + test_work\n",
    "        current_work = 0\n",
    "\n",
    "        model = build_transformer_with_attention(CONFIG['look_back'], X.shape[2])\n",
    "        model.fit(\n",
    "            X_train_full,\n",
    "            [y_train_full, np.zeros((len(y_train_full), 2, CONFIG['look_back'], CONFIG['look_back']))],\n",
    "            epochs=CONFIG['epochs'],\n",
    "            batch_size=CONFIG['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        current_work += training_work\n",
    "        progress_percent = (current_work / total_work) * 100\n",
    "        print(f\"{stock}: {progress_percent:.0f}%\", end='\\r')\n",
    "\n",
    "        os.makedirs(\"model\", exist_ok=True)\n",
    "        model_path = os.path.join(\"model\", f\"{stock}.keras\")\n",
    "        model.save(model_path)\n",
    "        logger.info(f\"Saved model for {stock} to {model_path}\")\n",
    "\n",
    "        predictions = []\n",
    "        history_X, history_y = X_train_full.tolist(), y_train_full.tolist()\n",
    "        for i in range(len(X_test)):\n",
    "            if i % 10 == 0:\n",
    "                logger.info(f\"Completed {i}/{len(X_test)} test steps for {stock}\")\n",
    "            if i % CONFIG['walkforward_retrain_step'] == 0 and i > 0:\n",
    "                logger.info(f\"Retraining at step {i}/{len(X_test)} for {stock}\")\n",
    "                model = build_transformer_with_attention(CONFIG['look_back'], X.shape[2])\n",
    "                model.fit(\n",
    "                    np.array(history_X),\n",
    "                    [np.array(history_y), np.zeros((len(history_y), 2, CONFIG['look_back'], CONFIG['look_back']))],\n",
    "                    epochs=CONFIG['epochs'],\n",
    "                    batch_size=CONFIG['batch_size'],\n",
    "                    verbose=0\n",
    "                )\n",
    "            pred, _ = model.predict(X_test[i:i+1], verbose=0)\n",
    "            predictions.append(pred[0][0])\n",
    "            history_X.append(X_test[i].tolist())\n",
    "            history_y.append(y_test[i].tolist())\n",
    "            current_work += 1\n",
    "            progress_percent = (current_work / total_work) * 100\n",
    "            print(f\"{stock}: {progress_percent:.0f}%\", end='\\r')\n",
    "\n",
    "        preds_inv = scaler.inverse_transform(np.repeat(np.array(predictions)[:, np.newaxis], X.shape[2], axis=1))[:, target_index]\n",
    "        y_true_inv = scaler.inverse_transform(np.repeat(y_test[:, np.newaxis], X.shape[2], axis=1))[:, target_index]\n",
    "\n",
    "        mse = mean_squared_error(y_true_inv, preds_inv)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true_inv, preds_inv)\n",
    "        r2 = r2_score(y_true_inv, preds_inv)\n",
    "\n",
    "        logger.info(f\"{stock} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "        print()  # Move to next line\n",
    "        print(f\"{stock}: Completed\")\n",
    "        return {'Stock': stock, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {stock}: {e}\")\n",
    "        return None\n",
    "\n",
    "def train_and_evaluate_transformer():\n",
    "    df = pd.read_csv(CONFIG['input_csv'])\n",
    "    stocks = df['symbol'].unique()\n",
    "    results = []\n",
    "\n",
    "    for stock in tqdm(stocks, desc=\"Evaluating stocks\", disable=True):  # Disable tqdm output\n",
    "        result = process_stock(stock, df)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(CONFIG['output_csv'], index=False)\n",
    "\n",
    "    logger.info(\"\\nEvaluation Results:\\n\" + result_df.to_string(index=False))\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    table = plt.table(cellText=result_df.round(4).values, colLabels=result_df.columns, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2)\n",
    "    plt.axis('off')\n",
    "    plt.title('Transformer Model Performance Metrics (Walk-Forward)', fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('transformer_results.png')\n",
    "    plt.close()\n",
    "\n",
    "    return result_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger.info(\"Starting Transformer model training and evaluation...\")\n",
    "    result_df = train_and_evaluate_transformer()\n",
    "    if result_df is not None:\n",
    "        logger.info(\"Evaluation complete.\")\n",
    "        print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
